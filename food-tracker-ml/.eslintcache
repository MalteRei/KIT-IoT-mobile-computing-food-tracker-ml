[{"C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\index.tsx":"1","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\reportWebVitals.ts":"2","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\App.tsx":"3","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\camera-stream-component\\CameraStream.tsx":"4","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\camera-feed-component\\CameraFeed.tsx":"5","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\video-prediction-component\\VideoPrediction.tsx":"6","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\helpers\\ImageModel.ts":"7"},{"size":500,"mtime":499162500000,"results":"8","hashOfConfig":"9"},{"size":425,"mtime":499162500000,"results":"10","hashOfConfig":"9"},{"size":236,"mtime":1611691451256,"results":"11","hashOfConfig":"9"},{"size":1617,"mtime":1611782250594,"results":"12","hashOfConfig":"9"},{"size":921,"mtime":1611785449915,"results":"13","hashOfConfig":"9"},{"size":1856,"mtime":1611785916110,"results":"14","hashOfConfig":"9"},{"size":3938,"mtime":1611785943712,"results":"15","hashOfConfig":"9"},{"filePath":"16","messages":"17","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"18"},"6oxpyz",{"filePath":"19","messages":"20","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"18"},{"filePath":"21","messages":"22","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"23","usedDeprecatedRules":"18"},{"filePath":"24","messages":"25","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"26","usedDeprecatedRules":"18"},{"filePath":"27","messages":"28","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"18"},{"filePath":"29","messages":"30","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"31","usedDeprecatedRules":"18"},{"filePath":"32","messages":"33","errorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"34"},"C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\index.tsx",[],["35","36"],"C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\reportWebVitals.ts",[],"C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\App.tsx",["37"],"import React from 'react';\nimport logo from './logo.svg';\nimport './App.css';\nimport CameraStream from './camera-stream-component/CameraStream';\n\nfunction App() {\n  return (\n    <CameraStream></CameraStream>\n  );\n}\n\nexport default App;\n","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\camera-stream-component\\CameraStream.tsx",["38"],"import React, { useState } from \"react\";\r\nimport CameraFeed from \"../camera-feed-component/CameraFeed\";\r\nimport VideoPrediction from \"../video-prediction-component/VideoPrediction\";\r\n\r\nconst CameraStream: React.FunctionComponent = (props) => {\r\n\r\n    const [cameraEnabled, setCameraEnabled] = useState(false);\r\n    const [cameraStream, setCameraStream] = useState<MediaStream | undefined>(undefined);\r\n\r\n    // Check if webcam access is supported.\r\n    const getUserMediaSupported = () => {\r\n        return !!(navigator.mediaDevices &&\r\n            navigator.mediaDevices.getUserMedia);\r\n    }\r\n\r\n    const enableCamera = () => {\r\n        // getUsermedia parameters to force video but not audio.\r\n        const constraints = {\r\n            video: true\r\n        };\r\n\r\n        // Activate the webcam stream.\r\n        navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {\r\n            setCameraStream(stream);\r\n            setCameraEnabled(true);\r\n        });\r\n    }\r\n\r\n\r\n    if (cameraEnabled) {\r\n        if(!cameraStream) {\r\n            return(\r\n                <p>Something went wrong with the camera.</p>\r\n            );\r\n        }\r\n        return (\r\n        <div>\r\n            <p>Camera is enabled</p>\r\n            <CameraFeed cameraStream={cameraStream}/>\r\n            </div>);\r\n    }\r\n\r\n    if (getUserMediaSupported()) {\r\n        return (<button onClick={enableCamera}>\r\n            Enable Webcam\r\n        </button>);\r\n    }\r\n\r\n\r\n\r\n\r\n    return (\r\n        //TODO create own error component\r\n        <h1>Camera is not supported by your browser</h1>\r\n    );\r\n}\r\n\r\n\r\nexport default CameraStream;","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\camera-feed-component\\CameraFeed.tsx",[],"C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\video-prediction-component\\VideoPrediction.tsx",["39"],"import React, { useEffect, useState } from 'react';\r\nimport ImageModel from '../helpers/ImageModel';\r\n\r\nexport interface IImageModelProps {\r\n    signaturePath: string,\r\n    videoElementToPredict: HTMLVideoElement | null\r\n}\r\nconst VideoPrediction: React.FunctionComponent<IImageModelProps> = (props) => {\r\n    const { signaturePath, videoElementToPredict } = props;\r\n    const [model, setModel] = useState<ImageModel | undefined>(undefined);\r\n\r\n    const loadModel = () => {\r\n        if (!model) {\r\n            const newModel = new ImageModel(signaturePath);\r\n            newModel.load()\r\n                .then(() => {\r\n                    setModel(newModel);\r\n                }).catch((err) => {\r\n                    //TODO handle error\r\n                    console.error(\"error loading model\");\r\n                    console.dir(err);\r\n                }\r\n                );\r\n        }\r\n    };\r\n\r\n    const cleanUpModel = () => {\r\n        if (model) {\r\n            model.dispose();\r\n            setModel(undefined);\r\n        }\r\n    };\r\n    useEffect(() => {\r\n        loadModel();\r\n        return cleanUpModel;\r\n    }, [signaturePath]);\r\n\r\n    if (!model || !model.isLoaded()) {\r\n        return (\r\n            <h2>\r\n                Model loading ...\r\n            </h2>\r\n        );\r\n    }\r\n    if(!videoElementToPredict){\r\n        return (\r\n            <h2>\r\n                Video element not yet there.\r\n            </h2>\r\n        )\r\n    }\r\n\r\n\r\n    const predictVideo = () => {\r\n        console.dir(model.predict(videoElementToPredict));\r\n         // Call this function again to keep predicting when the browser is ready.\r\n        //window.requestAnimationFrame(predictVideo);\r\n    }\r\n\r\n    videoElementToPredict.addEventListener('loadeddata', predictVideo);\r\n    return (\r\n        <p>Prediction running.</p>\r\n    );\r\n\r\n\r\n}\r\n\r\nexport default VideoPrediction;","C:\\Users\\Malte\\Documents\\GitHub\\KIT-IoT-mobile-computing-food-tracker-ml\\food-tracker-ml\\src\\helpers\\ImageModel.ts",["40","41"],"import * as tf from '@tensorflow/tfjs';\r\n//import { readFileSync } from 'fs';\r\nimport signatureDataFile from '../model/signature.json';\r\nclass ImageModel {\r\n\r\n    private signature: any;\r\n    private modelPath: string;\r\n    private height: number;\r\n    private width: number;\r\n    private outputName: string;\r\n    private outputKey = \"Confidences\";\r\n    private classes: string[];\r\n    private model?: tf.GraphModel;\r\n\r\n    public constructor(signaturePath: string) {\r\n        console.dir(signaturePath);\r\n       /* const signatureData = readFileSync(signaturePath, \"utf8\");\r\n        console.dir(signatureData);\r\n        this.signature = JSON.parse(signatureData);*/\r\n        console.dir(signatureDataFile);\r\n        this.signature = signatureDataFile;\r\n        this.modelPath = `file:../model/${this.signature.filename}`;\r\n        [this.width, this.height] = this.signature.inputs.Image.shape.slice(1, 3);\r\n        this.outputName = this.signature.outputs[this.outputKey].name;\r\n        this.classes = this.signature.classes.Label;\r\n    }\r\n\r\n    public async load() {\r\n        this.model = await tf.loadGraphModel(this.modelPath);\r\n    }\r\n\r\n    public dispose(): void {\r\n        if (this.model) {\r\n            this.model.dispose();\r\n            this.model = undefined;\r\n        }\r\n    }\r\n\r\n    public isLoaded(): boolean {\r\n        return (this.model != undefined);\r\n    }\r\n\r\n    public predict(toPredict: tf.Tensor3D | ImageData | HTMLImageElement | HTMLCanvasElement |\r\n        HTMLVideoElement) {\r\n        const tensorToPredict = tf.tidy(() => {\r\n            if (!(toPredict instanceof tf.Tensor)) {\r\n                return tf.browser.fromPixels(toPredict);\r\n            } else {\r\n                return toPredict;\r\n            }            \r\n        });\r\n        const result = this.predictTensor(tensorToPredict);\r\n        tensorToPredict.dispose();\r\n        return result;\r\n    }\r\n    private predictTensor(image: tf.Tensor) {\r\n        /*\r\n        Given an input image decoded by tensorflow as a tensor,\r\n        preprocess the image into pixel values of [0,1], center crop to a square\r\n        and resize to the image input size, then run the prediction!\r\n         */\r\n        if (!!this.model) {\r\n            const [imgHeight, imgWidth] = image.shape.slice(0, 2);\r\n            // convert image to 0-1\r\n            const normalizedImage = tf.div(image, tf.scalar(255));\r\n            // make into a batch of 1 so it is shaped [1, height, width, 3]\r\n            const reshapedImage: tf.Tensor4D = normalizedImage.reshape([1, ...normalizedImage.shape]);\r\n            // center crop and resize\r\n            let top = 0;\r\n            let left = 0;\r\n            let bottom = 1;\r\n            let right = 1;\r\n            if (imgHeight != imgWidth) {\r\n                // the crops are normalized 0-1 percentage of the image dimension\r\n                const size = Math.min(imgHeight, imgWidth);\r\n                left = (imgWidth - size) / 2 / imgWidth;\r\n                top = (imgHeight - size) / 2 / imgHeight;\r\n                right = (imgWidth + size) / 2 / imgWidth;\r\n                bottom = (imgHeight + size) / 2 / imgHeight;\r\n            }\r\n            const croppedImage = tf.image.cropAndResize(\r\n                reshapedImage, [[top, left, bottom, right]], [0], [this.height, this.width]\r\n            );\r\n            const results = this.model.execute(\r\n                { [this.signature.inputs.Image.name]: croppedImage }, this.outputName\r\n            ) as tf.Tensor;\r\n            const resultsArray = results.dataSync();\r\n            return {\r\n                [this.outputKey]: this.classes.reduce(\r\n                    (acc, class_, idx) => {\r\n                        return { [class_]: resultsArray[idx], ...acc }\r\n                    }, {}\r\n                )\r\n            }\r\n        } else {\r\n            console.error(\"Model not loaded, please await this.load() first.\");\r\n        }\r\n    }\r\n}\r\n\r\nexport default ImageModel;",{"ruleId":"42","replacedBy":"43"},{"ruleId":"44","replacedBy":"45"},{"ruleId":"46","severity":1,"message":"47","line":2,"column":8,"nodeType":"48","messageId":"49","endLine":2,"endColumn":12},{"ruleId":"46","severity":1,"message":"50","line":3,"column":8,"nodeType":"48","messageId":"49","endLine":3,"endColumn":23},{"ruleId":"51","severity":1,"message":"52","line":36,"column":8,"nodeType":"53","endLine":36,"endColumn":23,"suggestions":"54"},{"ruleId":"55","severity":1,"message":"56","line":40,"column":28,"nodeType":"57","messageId":"58","endLine":40,"endColumn":30},{"ruleId":"55","severity":1,"message":"56","line":73,"column":27,"nodeType":"57","messageId":"58","endLine":73,"endColumn":29},"no-native-reassign",["59"],"no-negated-in-lhs",["60"],"@typescript-eslint/no-unused-vars","'logo' is defined but never used.","Identifier","unusedVar","'VideoPrediction' is defined but never used.","react-hooks/exhaustive-deps","React Hook useEffect has missing dependencies: 'cleanUpModel' and 'loadModel'. Either include them or remove the dependency array.","ArrayExpression",["61"],"eqeqeq","Expected '!==' and instead saw '!='.","BinaryExpression","unexpected","no-global-assign","no-unsafe-negation",{"desc":"62","fix":"63"},"Update the dependencies array to be: [cleanUpModel, loadModel, signaturePath]",{"range":"64","text":"65"},[1117,1132],"[cleanUpModel, loadModel, signaturePath]"]